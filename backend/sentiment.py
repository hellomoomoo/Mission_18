# í•œêµ­ì–´ ë¦¬ë·° ê°ì„± ë¶„ì„ ëª¨ë“ˆ
# nlp04/korean_sentiment_analysis_kcelectra ëª¨ë¸ ì‚¬ìš©

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥
# ë§¤ë²ˆ ë¡œë“œí•˜ë©´ ëŠë¦¬ë‹ˆê¹Œ í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ì¬ì‚¬ìš©

_model = None
_tokenizer = None


def load_model():
    """
    ê°ì„± ë¶„ì„ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    ì²˜ìŒ í•œ ë²ˆ ì‹¤í–‰, ì´í›„ë¡œëŠ” ìºì‹±ëœ ëª¨ë¸ ì‚¬ìš©

    Returns:
        model: ê°ì„± ë¶„ì„ìš© íŒŒì¸íŠœë‹ëœ ëª¨ë¸
        tokenizer: í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    """

    global _model, _tokenizer

    # ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì¬ë¡œë“œí•˜ì§€ ì•ŠìŒ
    if _model is not None and _tokenizer is not None:
        return _model, _tokenizer
    
    print("ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤! âš™")

    # í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ ì´ë¦„ ì§€ì •
    model_name = "nlp04/korean_sentiment_analysis_kcelectra"

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    _tokenizer = AutoTokenizer.from_pretrained(model_name)

    # ëª¨ë¸ ë¡œë“œ
    # AutoModelForSequenceClassification: í…ìŠ¤íŠ¸ ë¶„ë¥˜ìš© ëª¨ë¸
    _model = AutoModelForSequenceClassification.from_pretrained(model_name)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    # eval(): í•™ìŠµ ëª¨ë“œê°€ ì•„ë‹Œ ì¶”ë¡ (ì˜ˆì¸¡) ëª¨ë“œë¡œ ì „í™˜
    # ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™” ë“±ì´ ë¹„í™œì„±í™”ë¨
    _model.eval()

    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    return _model, _tokenizer

# í´ë˜ìŠ¤ labelì´ 2ê°œê°€ ì•„ë‹ˆë¼ 11ê°œì¸ ê±¸ ê¹¨ë‹«ê³ ë‚˜ì„œ ìˆ˜ì • ë“¤ì–´ê°
def analyze_sentiment(text: str) -> float:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ 0~1 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë°˜í™˜
    """

    # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    if not text or not text.strip():
        return 0.5

    _model, _tokenizer = load_model()
    
    # í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜ì‹œí‚¬ ê²ƒ
    inputs = _tokenizer(
        text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=512
    )

    # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì¶”ë¡  ì‹œì—ëŠ” í•„ìš” ì—†ìŒ, ë©”ëª¨ë¦¬ ì ˆì•½)
    with torch.no_grad():
        # ëª¨ë¸ì— ì…ë ¥ ì „ë‹¬í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
        # outputs.logits: ê° í´ë˜ìŠ¤(ê¸ì •/ë¶€ì •)ì— ëŒ€í•œ raw ì ìˆ˜
        outputs = _model(**inputs)

    # logitsë¥¼ í™•ë¥ ë¡œ ë³€í™˜
    # softmax: ê° í´ë˜ìŠ¤ì˜ ì ìˆ˜ë¥¼ 0~1 ì‚¬ì´ í™•ë¥ ë¡œ ë³€í™˜ (í•©ì´ 1ì´ ë˜ëŠ” ê±°)
    # dim=1: ë§ˆì§€ë§‰ ì°¨ì›(í´ë˜ìŠ¤ ì°¨ì›)ì— ëŒ€í•´ softmax ì ìš©
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)

    # -----ë””ë²„ê¹…: í´ë˜ìŠ¤ ë ˆì´ë¸” í™•ì¸-----
    # print(f"\nëª¨ë¸ í´ë˜ìŠ¤ ë ˆì´ë¸”: {_model.config.id2label}")
    # print(f"í™•ë¥  ë¶„í¬: {probabilities[0].tolist()}")
    # ----------------------------------

    # ê°ì • ì¸ë±ìŠ¤ ë§¤í•‘ - ë””ë²„ê¹… í›„ ì¶”ê°€

    positive_indices = [0, 1, 2, 3, 4]
    # 0(ê¸°ì¨), 1(ê³ ë§ˆìš´), 2(ì„¤ë ˆëŠ”), 3(ì‚¬ë‘í•˜ëŠ”), 4(ì¦ê±°ìš´)
    negative_indices = [7, 8, 9, 10]
    # 7(ìŠ¬í””), 8(í˜ë“¦), 9(ì§œì¦ë‚¨), 10(ê±±ì •ìŠ¤ëŸ¬ìš´)
    neutral_indices = [5, 6]
    # 5(ì¼ìƒì ì¸), 6(ìƒê°ì´ ë§ì€)

    # ê°ì • ê·¸ë£¹ì˜ í™•ë¥  í•©ê³„ë¥¼ ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ í•œì¤„ì½”ë”©
    positive_score = sum(probabilities[0][i].item() for i in positive_indices)
    negative_score = sum(probabilities[0][i].item() for i in negative_indices)
    neutral_score = sum(probabilities[0][i].item() for i in neutral_indices)

    # ê¸ì • +ì¤‘ë¦½*0.5 ë¹„ìœ¨ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
    # ì¤‘ë¦½ì€ ì ˆë°˜ë§Œ ê¸ì •ìœ¼ë¡œ ê³„ì‚°
    total = positive_score + negative_score + neutral_score

    if total == 0:
        return 0.5
    
    # ê¸ì • ë¹„ìœ¨ ê³„ì‚° (ì¤‘ë¦½ì€ 0.5 ê°€ì¤‘ì¹˜)
    sentiment_score = (positive_score + neutral_score*0.5) / total

    return sentiment_score


def analyze_sentiment_batch(texts: list) -> list:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë¶„ì„ (ë°°ì¹˜ ì²˜ë¦¬)
    """
    if not texts:
        return []
    
    processed_texts = []
    empty_indices = []
    
    for i, text in enumerate(texts):
        if text and text.strip():
            processed_texts.append(text)
        else:
            empty_indices.append(i)
    
    if not processed_texts:
        return [0.5] * len(texts)
    
    _model, _tokenizer = load_model()
    
    inputs = _tokenizer(
        processed_texts,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=512
    )
    
    with torch.no_grad():
        outputs = _model(**inputs)
    
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
    
    # ê°ì • ì¸ë±ìŠ¤ ë§¤í•‘
    positive_indices = [0, 1, 2, 3, 4]
    negative_indices = [7, 8, 9, 10]
    neutral_indices = [5, 6]
    
    scores = []
    for i in range(len(processed_texts)):
        positive_score = sum(probabilities[i][idx].item() for idx in positive_indices)
        negative_score = sum(probabilities[i][idx].item() for idx in negative_indices)
        neutral_score = sum(probabilities[i][idx].item() for idx in neutral_indices)
        
        total = positive_score + negative_score + neutral_score
        
        if total == 0:
            scores.append(0.5)
        else:
            # ê´„í˜¸ ì¶”ê°€!
            sentiment_score = (positive_score + neutral_score * 0.5) / total
            scores.append(sentiment_score)
    
    # ë¹ˆ í…ìŠ¤íŠ¸ ìœ„ì¹˜ì— ì¤‘ë¦½ ì ìˆ˜ ì‚½ì…
    for idx in empty_indices:
        scores.insert(idx, 0.5)
    
    return scores
    


# í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œë§Œ ì‘ë™)
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ì˜ˆì‹œ
    test_reviews = [
        "ì •ë§ ê°ë™ì ì¸ ì˜í™”ì˜€ì–´ìš”! ìµœê³ !",
        "ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤. ë³„ë¡œì˜ˆìš”.",
        "ê·¸ëƒ¥ í‰ë²”í•œ ì˜í™”ë„¤ìš”",
        "ì—°ê¸°ê°€ ë„ˆë¬´ ì¢‹ì•˜ê³  ìŠ¤í† ë¦¬ë„ íƒ„íƒ„í–ˆì–´ìš”",
        "ëˆ ì•„ê¹Œì›Œìš” ã… ã… "
    ]
    
    print("\n---ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸---\n")
    
    for review in test_reviews:
        score = analyze_sentiment(review)
        print(f"ë¦¬ë·°: {review}")
        print(f"ê°ì„± ì ìˆ˜: {score:.3f}")
        
        # ì ìˆ˜ì— ë”°ë¥¸ ë ˆì´ë¸” ì¶œë ¥
        if score > 0.7:
            sentiment = "ğŸ˜Š ê¸ì •"
        elif score < 0.3:
            sentiment = "ğŸ˜ ë¶€ì •"
        else:
            sentiment = "ğŸ˜ ì¤‘ë¦½"
        
        print(f"íŒë‹¨: {sentiment}\n")