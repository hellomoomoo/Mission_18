# í•œêµ­ì–´ ë¦¬ë·° ê°ì„± ë¶„ì„ ëª¨ë“ˆ
# nlp04/korean_sentiment_analysis_kcelectra ëª¨ë¸ ì‚¬ìš©

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥
# ë§¤ë²ˆ ë¡œë“œí•˜ë©´ ëŠë¦¬ë‹ˆê¹Œ í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ì¬ì‚¬ìš©

_model = None
_tokenizer = None


def load_model():
    """
    ê°ì„± ë¶„ì„ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    ì²˜ìŒ í•œ ë²ˆ ì‹¤í–‰, ì´í›„ë¡œëŠ” ìºì‹±ëœ ëª¨ë¸ ì‚¬ìš©

    Returns:
        model: ê°ì„± ë¶„ì„ìš© íŒŒì¸íŠœë‹ëœ ëª¨ë¸
        tokenizer: í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    """

    global _model, _tokenizer

    # ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì¬ë¡œë“œí•˜ì§€ ì•ŠìŒ
    if _model is not None and _tokenizer is not None:
        return _model, _tokenizer
    
    print("ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤! âš™")

    # í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ ì´ë¦„ ì§€ì •
    model_name = "nlp04/korean_sentiment_analysis_kcelectra"

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    _tokenizer = AutoTokenizer.from_pretrained(model_name)

    # ëª¨ë¸ ë¡œë“œ
    # AutoModelForSequenceClassification: í…ìŠ¤íŠ¸ ë¶„ë¥˜ìš© ëª¨ë¸
    _model = AutoModelForSequenceClassification.from_pretrained(model_name)

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    # eval(): í•™ìŠµ ëª¨ë“œê°€ ì•„ë‹Œ ì¶”ë¡ (ì˜ˆì¸¡) ëª¨ë“œë¡œ ì „í™˜
    # ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™” ë“±ì´ ë¹„í™œì„±í™”ë¨
    _model.eval()

    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    return _model, _tokenizer

def analyze_sentiment(text: str) -> float:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ê°ì„±ì„ ë¶„ì„í•˜ì—¬ 0~1 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë°˜í™˜

    Args:
        text: ë¶„ì„í•  ë¦¬ë·° í…ìŠ¤íŠ¸ (ex: "ì‹œê°„ ê°€ëŠ” ì¤„ ëª¨ë¥´ê³  ì¬ë°Œê²Œ ë´¤ìŒ")

    Returns:
        float: ê°ì„± ì ìˆ˜
            - 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê¸ì •ì 
            - 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¶€ì •ì  (0.5 ê·¼ì²˜ë©´ ì¤‘ë¦½)
    """

    # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    if not text or not text.strip():
        return 0.5

    _model, _tokenizer = load_model()
    
    # í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜ì‹œí‚¬ ê²ƒ
    inputs = _tokenizer(
        text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=512
    )

    # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì¶”ë¡  ì‹œì—ëŠ” í•„ìš” ì—†ìŒ, ë©”ëª¨ë¦¬ ì ˆì•½)
    with torch.no_grad():
        # ëª¨ë¸ì— ì…ë ¥ ì „ë‹¬í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
        # outputs.logits: ê° í´ë˜ìŠ¤(ê¸ì •/ë¶€ì •)ì— ëŒ€í•œ raw ì ìˆ˜
        outputs = _model(**inputs)

    # logitsë¥¼ í™•ë¥ ë¡œ ë³€í™˜
    # softmax: ê° í´ë˜ìŠ¤ì˜ ì ìˆ˜ë¥¼ 0~1 ì‚¬ì´ í™•ë¥ ë¡œ ë³€í™˜ (í•©ì´ 1ì´ ë˜ëŠ” ê±°)
    # dim=1: ë§ˆì§€ë§‰ ì°¨ì›(í´ë˜ìŠ¤ ì°¨ì›)ì— ëŒ€í•´ softmax ì ìš©
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)


    # ê¸ì • í™•ë¥  ì¶”ì¶œ
    # probabilities[0]: ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ê²°ê³¼
    # .item(): í…ì„œì—ì„œ íŒŒì´ì¬ ìˆ«ìë¡œ ë³€í™˜
    positive_score = probabilities[0][0].item() # ì¸ë±ìŠ¤ ì˜ëª»ë˜ì–´ ìˆì–´ì„œ ìˆ˜ì • 1 -> 0

    return positive_score

def analyze_sentiment_batch(texts: list) -> list:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë¶„ì„ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë” ë¹ ë¦„)

    Args:
        texts: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        list: ê° í…ìŠ¤íŠ¸ì˜ ê°ì„± ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
    
    Example:
        >>> analyze_sentiment_batch(["ì¢‹ì•„ìš”", "ë³„ë¡œì˜ˆìš”", "ê·¸ëƒ¥ ê·¸ë˜ìš”"])
        [0.92, 0.15, 0.48]
    """

     # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    if not texts:
        return []
    
    # ë¹ˆ ë¬¸ìì—´ í•„í„°ë§ ë° ì¤‘ë¦½ ì ìˆ˜ í• ë‹¹
    processed_texts = []
    empty_indices = []
    
    for i, text in enumerate(texts):
        if text and text.strip():
            processed_texts.append(text)
        else:
            empty_indices.append(i)
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¤‘ë¦½ ì ìˆ˜ ë°˜í™˜
    if not processed_texts:
        return [0.5] * len(texts)
    
    # ëª¨ë¸ ë¡œë“œ
    model, tokenizer = load_model()
    
    # ë°°ì¹˜ í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(
        processed_texts,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=512
    )
    
    # ë°°ì¹˜ ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(**inputs)
    
    # í™•ë¥  ë³€í™˜
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
    
    # ê¸ì • í™•ë¥  ì¶”ì¶œ
    positive_scores = probabilities[:, 1].tolist()
    
    # ë¹ˆ í…ìŠ¤íŠ¸ ìœ„ì¹˜ì— ì¤‘ë¦½ ì ìˆ˜ ì‚½ì…
    for idx in empty_indices:
        positive_scores.insert(idx, 0.5)
    
    return positive_scores


# í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œë§Œ ì‘ë™)
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ì˜ˆì‹œ
    test_reviews = [
        "ì •ë§ ê°ë™ì ì¸ ì˜í™”ì˜€ì–´ìš”! ìµœê³ !",
        "ì‹œê°„ ë‚­ë¹„ì˜€ìŠµë‹ˆë‹¤. ë³„ë¡œì˜ˆìš”.",
        "ê·¸ëƒ¥ í‰ë²”í•œ ì˜í™”ë„¤ìš”",
        "ì—°ê¸°ê°€ ë„ˆë¬´ ì¢‹ì•˜ê³  ìŠ¤í† ë¦¬ë„ íƒ„íƒ„í–ˆì–´ìš”",
        "ëˆ ì•„ê¹Œì›Œìš” ã… ã… "
    ]
    
    print("\n---ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸---\n")
    
    for review in test_reviews:
        score = analyze_sentiment(review)
        print(f"ë¦¬ë·°: {review}")
        print(f"ê°ì„± ì ìˆ˜: {score:.3f}")
        
        # ì ìˆ˜ì— ë”°ë¥¸ ë ˆì´ë¸” ì¶œë ¥
        if score > 0.7:
            sentiment = "ğŸ˜Š ê¸ì •"
        elif score < 0.3:
            sentiment = "ğŸ˜ ë¶€ì •"
        else:
            sentiment = "ğŸ˜ ì¤‘ë¦½"
        
        print(f"íŒë‹¨: {sentiment}\n")